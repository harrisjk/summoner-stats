{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/title_slide.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>Project Details:</b>\n",
    "    <ul>\n",
    "        <li>Project title: Decoding Summoner's Rift</li>\n",
    "        <li>Project description: Creating and analyzing a summoner-specific dataset of League of Legends ranked matches</li>\n",
    "        <li>APIs used: <a href='https://developer.riotgames.com/'>Riot API</a></li>\n",
    "        <li>Project creator: Harrison Knapp</li>\n",
    "        <li>Creator background: Previous work with NASA and NOAA has focused on leveraging geospatial analytics and\n",
    "remote sensing to better understand natural and human-built systems (work with Python, R, and MATLAB)</li>\n",
    "        <li>Undergrad: B.S. in GeoDesign, B.A. Earth Sciences</li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "<h1>Introduction</h1>\n",
    "\n",
    "<h3>What is League?</h3>\n",
    "\n",
    "<p>\n",
    "    <i>League of Legends</i> (LoL) is a multiplayer online battle arena computer game developed and published by Riot Games. Since its release in October 2009, it has become a world leader in the esports space and continues to lead global revenue charts for free-to-play games. During a standard LoL match, two teams of five players go head-to-head in a strategic battle for control of the map. Each player—referred to as a “summoner”—commands a “champion,” a character with unique abilities that occupies a specific role on the team. Together, summoners engage in PvP combat with the enemy team, push to gain control over map objectives, and gradually become stronger by collecting experience points and purchasing items to gain an edge over enemy summoners. The game is won once a team pushes their way through the opposing team’s defending turrets and destroys their nexus, a large structure that serves as the heart of the enemy team’s base.<br><br>Due to the League’s high skill cap and increasingly popular “Ranked” game mode (games played to advance up a ladder, with the highest tier being professional play), there is an ever-present desire by players to learn and improve. While there certainly are well-established micro and macro strategies that bring success, there is still much to be understood about which in-game factors most significantly contribute to win rate. Machine learning techniques may be useful in this context, as clustering algorithms and neural networks can help us predict win rate given a range of input parameters. However, training a model requires a massive database of match and player statistics, something that has not yet been aggregated nor centralized.\n",
    "</p>\n",
    "\n",
    "<h3>The Objective</h3>\n",
    "\n",
    "<p>\n",
    "    The original goal of this project was to create a dataset of this magnitude and a framework for future ML exploration through leveraging Riot Games' League of Legends API. By using the Riot API to query the match history of high elo players, isolating other players in said matches, and repeating the process for their own match histories, a dataset of individual games and associated in-game/player stats can be made. Such a table would have rows for each match corresponding to an individual matchId, while the columns would include information such as which team secured \"first blood,\" how many dragons (a neutral objective that boosts stats) were slain by each team, the damage dealt and gold earned by each individual player, and much more. This dataset could then be used in various ML explorations aimed at understanding what factors lead a team on Summoner's Rift to victory.<br><img src='figures/pretty_stats.jpeg'><br>However, after conducting futher research into this starting objective, I discovered a few Kaggle users that had already created such a dataset. <a href='https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min'>One developer in particular</a> had created nearly exactly what I had set out to make in the first place: a dataset with 10,000+ matches at Diamond rank or higher containing stats from the first 10 minutes of the game, the critical first moments of a League match where the momentum is set and the winner is typically decided. Finding this encouraged me to think about how I could differentiate myself from these already created datasets. For starters, I still wanted to write a series of scripts that would create a similar high elo match database, since the existing dataset is a year old. Each new year marks the start of a new season in League which brings along with it a host of fundamental gameplay updates, item tweaks, champion balancing, and other alterations that change how the game is played at all levels. This year, Riot kicked off season 11 by implementing an entirely new item system, scrapping the old one and completely changing how players viewed itemization and gameplay as a whole. With that in mind, I still saw creating a large dataset of matches as an important and worthwhile task, especially for the machine learning exploration I intend on doing in the future.<br><br>But I still wanted to push things further. What else could I do with my newfound understanding of the Riot API? How else can machine learning help players win games? It was at that point that I realized I could also implement a player-centric approach to my database collection plans: create a database of ranked matches for a single top-level player (or anyone, for that matter) and extract player stats to see what wins and loses them games. I thought the perfect candidate for this would be Tyler1, the biggest name in League streaming and one of the largest content creators on Twitch. Tyler plays ranked League for 8+ hours a day, 7 days a week, and is currently only playing the top lane position. This makes him a perfect candidate for an ML exploration, as there are already a few variables being held constant. With this new direction and renewed excitement, I started working.<br><img src='figures/tyler_reformed.jpeg'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Revision &amp; Implementation</h1>\n",
    "\n",
    "<p>\n",
    "    The code below is the complete workflow for this project and accomplishes the following tasks:\n",
    "    <ul>\n",
    "        <li>Compile a list of matchIds for a given summoner and time period (in this case Tyler1)</li>\n",
    "        <li>Request match data from the Riot API for each of those games in order</li>\n",
    "        <li>Store the player and team stats (extracted features) in a Pandas dataframe and export to CSV</li>\n",
    "        <li>Process that CSV in parallel using PySpark to get average stats for each champion (in-game character) and export to CSV (ex. win rate and average kills per game for Aatrox)</li>\n",
    "        <li>Convert both the original match data and champion-specific stats CSVs to JSON documents</li>\n",
    "        <li>Upload those JSON documents to a Firebase realtime database (summoner-stats) as summoner_matches and champ_stats</li>\n",
    "        <li>Utilize ipywidgets to build a front-end for querying the Firebase database</li>\n",
    "    </ul>\n",
    "    This notebook is organized such that the database front-end comes first, since the Firebase database has already been populated with the summoner_matches and champ_stats JSON documents. The component of the project not shown are the environment setup files stored in the GitHub repo that help guide Binder and the repo2docker library when setting up the Docker image/JupyterHub cloud computing environment. By going to <a href='https://mybinder.org/'>mybinder.org</a> and pasting in the GitHub repo link, a JupyterHub instance will be spun up on a cloud server with all of the required Python libraries and Spark/Hadoop binaries installed. This way, anyone can run the code for themselves to test out the process without having to worry about setting up the correct environment on their local machine.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all required libraries\n",
    "from riotwatcher import LolWatcher\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as fc\n",
    "\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import ipywidgets as ipw\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/iblitz.jpeg'>\n",
    "\n",
    "<h1>Database Query: Matches</h1>\n",
    "\n",
    "<p>\n",
    "    The code below allows users to query the summoner_matches component of the Firebase database, i.e. the JSON document that stores the raw feature information from each of the matches stored from the matchId list.<br><br>First, run the cell immediately below this one to initialize the ipywidgets. There will be an option to specify the search field (win, first blood takedown, etc.) and the search input (true or false). Once both of these options have been selected, run the second cell to receive the output for the query, which in this case has been converted to a string for easy printing. The resulting strings will correspond to each individual match and will print out the champion the summoner was playing as (in championId form), their KDA (kill/death/assist numbers), and whether or not they won the match.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### WIDGET INIT CELL\n",
    "\n",
    "printmd('<h2>MATCHES QUERY PARAMS:</h2>')\n",
    "\n",
    "# Field select\n",
    "field_select = ipw.Dropdown(\n",
    "    options=[('Win', 1), ('First Blood Takedown', 2), ('First Tower Takedown', 3), ('First Baron', 4)],\n",
    "    value=1,\n",
    "    description='Number:',\n",
    ")\n",
    "\n",
    "# Search term\n",
    "search_term = ipw.Dropdown(\n",
    "    options=[('True', 1), ('False', 2)],\n",
    "    value=1,\n",
    "    description='Input:',\n",
    ")\n",
    "\n",
    "# Build accordion\n",
    "accordion = ipw.Accordion(children=[field_select, search_term])\n",
    "accordion.set_title(0, 'Search Field')\n",
    "accordion.set_title(1, 'Search Input')\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXECUTE QUERY\n",
    "\n",
    "# Take widget input and store as variables\n",
    "field_options = {\n",
    "    1 : 'win',\n",
    "    2 : 'firstBloodTakedown',\n",
    "    3 : 'firstTowerTakedown',\n",
    "    4 : 'team_firstBaron'\n",
    "}\n",
    "if search_term.value == 1:\n",
    "    term_value = True\n",
    "else:\n",
    "    term_value = False\n",
    "term_key = field_options[field_select.value]\n",
    "\n",
    "# Execute query to firebase\n",
    "url = 'https://summoner-stats-c8f6a-default-rtdb.firebaseio.com/summoner_matches.json'\n",
    "r = requests.get(url)\n",
    "match_list = json.loads(r.text)\n",
    "\n",
    "for match in match_list:\n",
    "    if match[term_key] == term_value:\n",
    "        champID = match['championId']\n",
    "        win_status = match['win']\n",
    "        kills = match['kills']\n",
    "        deaths = match['deaths']\n",
    "        assists = match['assists']\n",
    "        \n",
    "        print('Summoner playing as champID = ' + str(champID) + '; KDA = '\n",
    "             + str(kills) + '/' + str(deaths) + '/' + str(assists) + '; Win = ' + str(win_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Database Query: Champion Stats</h1>\n",
    "\n",
    "<p>\n",
    "    The code below allows users to query the champ_stats component of the Firebase database, i.e. the JSON document that stores the feature information averaged by champion from each of the matches stored from the matchId list.<br><br>First, run the cell immediately below this one to initialize the ipywidgets. There will be an option to specify the search type (champion ID or name) and the search input (either the ID as defined by Riot CommunityDragon or the name of the champion). Once both of these options have been specified, run the second cell to receive the output for the query, which in this case has been converted to a string for easy printing. The resulting string will contain all of the average stats for that summoner's champion, as well as the number of games that were taken into account for the aggregation.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIDGET INIT CELL\n",
    "\n",
    "printmd('<h2>CHAMP STATS QUERY PARAMS:</h2>')\n",
    "\n",
    "# Field select\n",
    "field_select = ipw.Dropdown(\n",
    "    options=[('Champion ID', 1), ('Champion Name', 2)],\n",
    "    value=1,\n",
    "    description='Number:',\n",
    ")\n",
    "\n",
    "# Search term\n",
    "search_term = ipw.Text(\n",
    "    value='Hello World',\n",
    "    placeholder='ID/Name',\n",
    "    description='Input:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Build accordion\n",
    "accordion = ipw.Accordion(children=[field_select, search_term])\n",
    "accordion.set_title(0, 'Search Type')\n",
    "accordion.set_title(1, 'Champion ID/Name (capitalized, no spaces)')\n",
    "display(accordion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXECUTE QUERY\n",
    "\n",
    "# Take widget input and store as variables\n",
    "field_options = {\n",
    "    1 : 'championID',\n",
    "    2 : 'championName',\n",
    "}\n",
    "if search_term.value.isnumeric():\n",
    "    term_value = int(search_term.value)\n",
    "else:\n",
    "    term_value = search_term.value\n",
    "term_key = field_options[field_select.value]\n",
    "\n",
    "# Execute query to firebase\n",
    "url = 'https://summoner-stats-c8f6a-default-rtdb.firebaseio.com/champ_stats.json'\n",
    "r = requests.get(url)\n",
    "stat_list = json.loads(r.text)\n",
    "\n",
    "for entry in stat_list:\n",
    "    if entry[term_key] == term_value:\n",
    "        championName = entry['championName']\n",
    "        avgKills = entry['avgKills']\n",
    "        avgDeaths = entry['avgDeaths']\n",
    "        avgAssists = entry['avgAssists']\n",
    "        avgF10csPerMin = entry['avgF10csPerMin']\n",
    "        avgF10goldPerMin = entry['avgF10goldPerMin']\n",
    "        avgF10xpPerMin = entry['avgF10xpPerMin']\n",
    "        avgTotalCS = entry['avgTotalCS']\n",
    "        avgVisionScore = entry['avgVisionScore']\n",
    "        championID = entry['championID']\n",
    "        championName = entry['championName']\n",
    "        games = entry['games']\n",
    "        winRate = entry['winRate']\n",
    "        \n",
    "        print(\"Average stats for Summoner's \" + str(championName) + \":\")\n",
    "        print('\\tAverage Kills:\\t\\t\\t\\t' + str(avgKills))\n",
    "        print('\\tAverage Deaths:\\t\\t\\t\\t' + str(avgDeaths))\n",
    "        print('\\tAverage Assists:\\t\\t\\t' + str(avgAssists))\n",
    "        print('\\tAverage CS/min (first 10 min):\\t\\t' + str(avgF10csPerMin))\n",
    "        print('\\tAverage Gold/min (first 10 min):\\t' + str(avgF10goldPerMin))\n",
    "        print('\\tAverage XP/min (first 10 min):\\t\\t' + str(avgF10xpPerMin))\n",
    "        print('\\tAverage Total CS:\\t\\t\\t' + str(avgTotalCS))\n",
    "        print('\\tAverage Vision score:\\t\\t\\t' + str(avgVisionScore))\n",
    "        print('\\tAverage Games analyzed:\\t\\t\\t' + str(games))\n",
    "        print('\\tAverage Win rate:\\t\\t\\t' + str(winRate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/heimer.jpeg'>\n",
    "\n",
    "<h1>Dataset Creation</h1>\n",
    "\n",
    "<p>\n",
    "    The code below executes all of the steps outlined above in the Revisions &amp; Implementation section. First, inputs such as your API key, region, summoner name, and input/output files must be defined. Then, each cell will accomplish a different task in the analysis process: get matchIds, ask the Riot API for match information, store in datasets, get average stats per champion using PySpark, and convert the CSVs to JSON documents. The code for uploading the resulting JSON datasets to Firebase is described in the following section.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUTS (for dataset creation)\n",
    "\n",
    "# League of Legends Watcher scrub parameters\n",
    "api_key = 'INSERT_API_KEY_HERE' # Riot api key\n",
    "region = 'na1'  # LoL region for analysis\n",
    "summoner_name = 'HULKSMASH1337' # LoL summoner name, in this case for Tyler1\n",
    "season = 13  # season as defined by CommunityDragon/Data/patches.json for MatchApiV4 query\n",
    "queue = 420  # ranked solo queue type\n",
    "\n",
    "\n",
    "### GLOBAL VARIABLES (for dataset creation)\n",
    "\n",
    "# In/out file names\n",
    "MIDs_name = 'MIDs'\n",
    "sumInfo_name = 'summoner_info'\n",
    "sumMatches_name = 'T1_example_matches'  # for routine deployment, change to 'summoner_matches'\n",
    "champInfo_name = 'champion'\n",
    "part_dir_name = 'pyspark-champ-stats'\n",
    "champStats_name = 'champ_stats'\n",
    "\n",
    "# Resulting paths\n",
    "base_path = 'data/'  # directory where all data files are stored\n",
    "MIDs_json = base_path + MIDs_name + '.json'\n",
    "sumInfo_json = base_path + sumInfo_name + '.json'\n",
    "sumMatches_csv = base_path + sumMatches_name + '.csv'\n",
    "sumMatches_json = base_path + sumMatches_name + '.json'\n",
    "part_dir = base_path + part_dir_name\n",
    "champStats_file = champStats_name + '.csv'\n",
    "champStats_csv = part_dir + '/' + champStats_file\n",
    "champStats_json = base_path + champStats_name + '.json'\n",
    "champInfo_json = champInfo_name + '.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get list of matchIds (MIDs)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for analysis\n",
    "lol_watcher = LolWatcher(api_key=api_key)  # create watcher object\n",
    "\n",
    "summoner = lol_watcher.summoner.by_name(region, summoner_name)  # create summoner object for T1\n",
    "print(summoner)\n",
    "\n",
    "with open(sumInfo_json, 'w', encoding='utf-8') as f:  # dump summoner info into JSON file\n",
    "    json.dump(summoner, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# Get total number of ranked games and iterations of 100 games needed to scrub API\n",
    "match_list = lol_watcher.match.matchlist_by_account(region, summoner['accountId'], season=season,\n",
    "                                                    queue=queue, begin_index=100)\n",
    "total_games = match_list['totalGames']  # get the total number of games given by API call\n",
    "iterations = math.ceil(total_games/100)  # figure out number of iterations necessary to get all game IDs\n",
    "\n",
    "\n",
    "# Create list of game IDs by iterating through match history\n",
    "game_ids = []\n",
    "for i in range(iterations):\n",
    "\n",
    "    begin_index = i*100\n",
    "    match_list = lol_watcher.match.matchlist_by_account(region, summoner['accountId'], season=season, queue=queue,\n",
    "                                                        begin_index=begin_index)\n",
    "    for match in match_list['matches']:\n",
    "        game_ids.append(match['gameId'])\n",
    "\n",
    "\n",
    "# Remove duplicates, export list to JSON formatted file\n",
    "game_ids_cleaned = []\n",
    "[game_ids_cleaned.append(x) for x in game_ids if x not in game_ids_cleaned]\n",
    "\n",
    "with open(MIDs_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(game_ids_cleaned, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get match information using MIDs list</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for analysis\n",
    "lol_watcher = LolWatcher(api_key=api_key)  # create watcher object\n",
    "\n",
    "# Initialize df\n",
    "header = ['matchId', 'championId', 'win', 'kills', 'deaths', 'assists',\n",
    "          'visionScore', 'controlWardsBought', 'totalGold', 'f10_goldPerMin',\n",
    "          'creepScore', 'f10_csPerMin', 'f10_csDiffPerMin', 'f10_xpPerMin', 'f10_xpDiffPerMin',\n",
    "          'firstBloodKill', 'firstBloodAssist', 'firstBloodTakedown',\n",
    "          'firstTowerKill', 'firstTowerAssist', 'firstTowerTakedown',\n",
    "          'team_firstDragon', 'team_firstHerald', 'team_firstBaron', 'team_dragonKills']\n",
    "df = pd.DataFrame(columns=header)\n",
    "\n",
    "# Load in match IDs from JSON\n",
    "f = open(MIDs_json)\n",
    "matches = json.load(f)\n",
    "num_matches = len(matches)\n",
    "\n",
    "\n",
    "# Iterate through matches\n",
    "match_counter = 0\n",
    "for match_id in matches:\n",
    "\n",
    "    time.sleep(2)\n",
    "    match_counter += 1\n",
    "    print('Now processing: ' + str(match_id) + ' (' + str(match_counter) + '/' + str(num_matches) + ')')\n",
    "\n",
    "    try:\n",
    "        match = lol_watcher.match.by_id(region=region, match_id=match_id)\n",
    "\n",
    "        # Get player ID and index\n",
    "        p_ID = 0\n",
    "        p_index = 0\n",
    "        p_counter = -1\n",
    "        for participant in match['participantIdentities']:\n",
    "            p_counter += 1\n",
    "            if participant['player']['summonerName'] == summoner_name:\n",
    "                pID = participant['participantId']\n",
    "                p_index = p_counter\n",
    "\n",
    "        # Get team ID and index\n",
    "        t_ID = match['participants'][p_index]['teamId']\n",
    "        t_index = 0\n",
    "        t_counter = -1\n",
    "        for team in match['teams']:\n",
    "            t_counter += 1\n",
    "            if team['teamId'] == t_ID:\n",
    "                t_index = t_counter\n",
    "\n",
    "        # Check top lane\n",
    "        if match['participants'][p_index]['timeline']['lane'] == 'TOP':\n",
    "\n",
    "            # Get stats\n",
    "            championId = match['participants'][p_index]['championId']\n",
    "\n",
    "            win = match['participants'][p_index]['stats']['win']\n",
    "            kills = match['participants'][p_index]['stats']['kills']\n",
    "            deaths = match['participants'][p_index]['stats']['deaths']\n",
    "            assists = match['participants'][p_index]['stats']['assists']\n",
    "\n",
    "            visionScore = match['participants'][p_index]['stats']['visionScore']\n",
    "            controlWardsBought = match['participants'][p_index]['stats']['visionWardsBoughtInGame']\n",
    "\n",
    "            totalGold = match['participants'][p_index]['stats']['goldEarned']\n",
    "            f10_goldPerMin = match['participants'][p_index]['timeline']['goldPerMinDeltas']['0-10']\n",
    "\n",
    "            creepScore = match['participants'][p_index]['stats']['totalMinionsKilled']\n",
    "            f10_csPerMin = match['participants'][p_index]['timeline']['creepsPerMinDeltas']['0-10']\n",
    "            if 'csDiffPerMinDeltas' in match['participants'][p_index]['timeline']:\n",
    "                f10_csDiffPerMin = match['participants'][p_index]['timeline']['csDiffPerMinDeltas']['0-10']\n",
    "            else:\n",
    "                f10_csDiffPerMin = None\n",
    "\n",
    "            f10_xpPerMin = match['participants'][p_index]['timeline']['xpPerMinDeltas']['0-10']\n",
    "            if 'xpDiffPerMinDeltas' in match['participants'][p_index]['timeline']:\n",
    "                f10_xpDiffPerMin = match['participants'][p_index]['timeline']['xpDiffPerMinDeltas']['0-10']\n",
    "            else:\n",
    "                f10_xpDiffPerMin = None\n",
    "\n",
    "            firstBloodKill = match['participants'][p_index]['stats']['firstBloodKill']\n",
    "            firstBloodAssist = match['participants'][p_index]['stats']['firstBloodAssist']\n",
    "            firstBloodTakedown = False\n",
    "            if firstBloodKill or firstBloodAssist:\n",
    "                firstBloodTakedown = True\n",
    "\n",
    "            firstTowerKill = match['participants'][p_index]['stats']['firstTowerKill']\n",
    "            firstTowerAssist = match['participants'][p_index]['stats']['firstTowerAssist']\n",
    "            firstTowerTakedown = False\n",
    "            if firstTowerKill or firstTowerAssist:\n",
    "                firstTowerTakedown = True\n",
    "\n",
    "            team_firstDragon = match['teams'][t_index]['firstDragon']\n",
    "            team_firstHerald = match['teams'][t_index]['firstRiftHerald']\n",
    "            team_firstBaron = match['teams'][t_index]['firstBaron']\n",
    "            team_dragonKills = match['teams'][t_index]['dragonKills']\n",
    "\n",
    "            # Add match data to pandas frame\n",
    "            row = [match_id, championId, win, kills, deaths, assists,\n",
    "                   visionScore, controlWardsBought, totalGold, f10_goldPerMin,\n",
    "                   creepScore, f10_csPerMin, f10_csDiffPerMin, f10_xpPerMin, f10_xpDiffPerMin,\n",
    "                   firstBloodKill, firstBloodAssist, firstBloodTakedown,\n",
    "                   firstTowerKill, firstTowerAssist, firstTowerTakedown,\n",
    "                   team_firstDragon, team_firstHerald, team_firstBaron, team_dragonKills]\n",
    "\n",
    "            df_length = len(df)\n",
    "            df.loc[df_length] = row\n",
    "\n",
    "    except Exception as inst:\n",
    "        print(inst)\n",
    "\n",
    "# Export df to CSV\n",
    "df.to_csv(sumMatches_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Leverage PySpark to get champ-specific average stats</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spark session\n",
    "spark = SparkSession.builder.appName('hextech').getOrCreate()\n",
    "\n",
    "# Process CSV in parallel using PySpark, export champion stats CSVs (each part is single row)\n",
    "df = spark.read.options(header=True, inferSchema=True).csv(sumMatches_csv)\n",
    "# df.printSchema()\n",
    "\n",
    "result = df.groupBy('championID').agg(fc.avg(fc.col('win').cast('double')).alias('winRate'),\n",
    "                                      fc.count('*').alias('games'),\n",
    "                                      fc.mean('kills').alias('avgKills'),\n",
    "                                      fc.mean('deaths').alias('avgDeaths'),\n",
    "                                      fc.mean('assists').alias('avgAssists'),\n",
    "                                      fc.mean('visionScore').alias('avgVisionScore'),\n",
    "                                      fc.mean('creepScore').alias('avgTotalCS'),\n",
    "                                      fc.mean('f10_goldPerMin').alias('avgF10goldPerMin'),\n",
    "                                      fc.mean('f10_csPerMin').alias('avgF10csPerMin'),\n",
    "                                      fc.mean('f10_xpPerMin').alias('avgF10xpPerMin')\n",
    "                                      )\n",
    "\n",
    "# result.show(100, False)\n",
    "result.printSchema()\n",
    "result.write.options(header=True, delimiter=',').csv(part_dir)\n",
    "\n",
    "# Merge single-row parts into summary CSV\n",
    "os.chdir(part_dir)\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "combined_csv.to_csv(champStats_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert output CSVs to JSON</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert matches CSV to JSON\n",
    "df_matches = pd.read_csv(sumMatches_csv)\n",
    "df_matches.to_json(path_or_buf=sumMatches_json, orient='records')\n",
    "\n",
    "\n",
    "# Add champ name to champ_stats from champion.json, convert to JSON\n",
    "df_champ_stats = pd.read_csv(champStats_csv)\n",
    "\n",
    "with open(champInfo_json, 'r') as f:\n",
    "    champs = json.loads(f.read())\n",
    "\n",
    "data = list()  # get champion info as list of lists [Name, ID]\n",
    "for item in champs['data']:\n",
    "    champ_name = champs['data'][item]['id']\n",
    "    champ_id = champs['data'][item]['key']\n",
    "\n",
    "    row = [champ_name, champ_id]\n",
    "    data.append(row)\n",
    "\n",
    "df_champs = pd.DataFrame(data, columns=['championName', 'championID'])  # convert data list to pd dataframe\n",
    "df_champs['championID'] = df_champs['championID'].astype(int)\n",
    "\n",
    "df_join = pd.merge(df_champ_stats, df_champs, on='championID')  # merge champ stats and info dfs, restructure cols\n",
    "cols = df_join.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_join = df_join[cols]\n",
    "\n",
    "df_join.to_json(path_or_buf=champStats_json, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Upload to Firebase</h1>\n",
    "\n",
    "<p>\n",
    "    The following code is used for uploading the summoner_matches and champ_stats JSON documents to a specified Firebase realtime databse. It has been commented out since the database has already been created and is ready to be queried using the ipywidget interface defined above.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://summoner-stats-c8f6a-default-rtdb.firebaseio.com/'\n",
    "# matches = 'data/summoner_matches.json'  # temp inputs for IDE testing\n",
    "# champ_stats = 'data/champ_stats.json'\n",
    "\n",
    "# # Load roster data to knapp-hw1 Firebase project\n",
    "# with open(matches) as f:  # load file in as list\n",
    "#     match_list = json.load(f)\n",
    "# match_data = json.dumps(match_list)  # convert list to JSON string\n",
    "# matches_url = url + '/summoner_matches.json'  # set url for upload\n",
    "# r = requests.put(matches_url, data=match_data)  # execute put\n",
    "# # print(r.text)  # print status if necessary\n",
    "\n",
    "# # Load chat data to knapp-hw1 Firebase project\n",
    "# with open(champ_stats) as f:\n",
    "#     champ_stats_list = json.load(f)\n",
    "# champ_stats_data = json.dumps(champ_stats_list)\n",
    "# champ_stats_url = url + '/champ_stats.json'\n",
    "# r = requests.put(champ_stats_url, data=champ_stats_data)\n",
    "# # print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>Process Diagram: </b>shown below is a rough diagram of the database creation process and the technologies used with added information about the Binder interface\n",
    "</p>\n",
    "\n",
    "<img src='figures/diagram.png'>\n",
    "\n",
    "<h1>Comments &amp; Conclusions</h1>\n",
    "\n",
    "<p>\n",
    "    Working on this project has been an absolute blast; I never thought that I would be able to bridge my understanding of programming and my passion for video games in such a tangible way. The possibilities for future ML explorations using this database creation platform/code as a backbone are endless, and I can't wait to get started chipping away at that original driving goal of understanding what wins and loses a game of League. In working on this project, I encountered many technologies and problems I had never worked with/through before: 504 error handling and time throttling my code so I didn't overload my API key limits, working with Firebase in a production setting, properly setting up Spark/Hadoop on a Docker container/JupyterHub cloud environment, and many other fun challenges to overcome. Altogether, I'm proud of what I've accomplished with this project and am looking forward to further polishing the tool as I move forward into the summer. My skills with database management and Python development have improved tremendously, and I can't wait to take that progress and continue to build on it as I move forward in my education and professional life.\n",
    "</p>\n",
    "\n",
    "<img src='figures/win_loss.png'>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
